{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNhONVDEVcsI",
    "outputId": "368748a5-ef51-4a14-a468-a36dd4b98a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.gurobi.com\n",
      "Requirement already satisfied: gurobipy in /usr/local/lib/python3.7/dist-packages (9.5.1)\n"
     ]
    }
   ],
   "source": [
    "#### The cutting stock object is the environment\n",
    "# %pip install -i https://pypi.gurobi.com gurobipy\n",
    "from gurobipy import GRB\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nfLY81WyPwoG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#### define transition object to hold the transition data\n",
    "class Transition(object):\n",
    "# s0_augmented, a0, r, is_done, s1_augmented, total\n",
    "\n",
    "    def __init__(self, s0_augmented, a0, r:float, is_done:bool, s1_augmented,action_info_0,total_0, total_1):\n",
    "          self.data = (s0_augmented, a0, r, is_done, s1_augmented, action_info_0, total_0, total_1)\n",
    "\n",
    "    @property\n",
    "    def s0(self): \n",
    "          return self.data[0]\n",
    "\n",
    "    @property\n",
    "    def a0(self): \n",
    "        return self.data[1]\n",
    "\n",
    "    @property\n",
    "    def reward(self): \n",
    "        return self.data[2]\n",
    "    \n",
    "    @property\n",
    "    def is_done(self): \n",
    "        return self.data[3]\n",
    "\n",
    "    @property\n",
    "    def s1(self): \n",
    "        return self.data[4]\n",
    "    \n",
    "    @property\n",
    "    def action_info_0(self): \n",
    "        return self.data[5]\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def total_0(self): \n",
    "        return self.data[6]\n",
    "\n",
    "    @property\n",
    "    def total_1(self): \n",
    "        return self.data[7]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "    \n",
    "    def __str__(self):\n",
    "        edge_num1 = len(self.data[0][1][1])\n",
    "        edge_num2 = len(self.data[-1][1][1])\n",
    "        result = 'transit from bipartite graph with edge' + str(edge_num1) + ' to ' + str(edge_num2) +' collecting the reward ' + str(self.data[2])\n",
    "            # return 'transit from bipartite graph ' + col_string1 + ' connects to ' + con_string1 + ' to ' + col_string2 + ' connects to ' + con_string2 +' collecting the reward ' + str(self.data[2])\n",
    "        return result\n",
    "        \n",
    "\n",
    "    \n",
    "############\n",
    "def show_final_solution(cut):\n",
    "    use = [math.ceil(i) for i in cut.ColumnSol_Val]\n",
    "    for i, p in enumerate(cut.current_patterns):\n",
    "        if use[i]>0:\n",
    "            print('Pattern ', i, ': how often we should cut: ', use[i])\n",
    "            print('----------------------')\n",
    "            for j,order in enumerate(p):\n",
    "                if order >0:\n",
    "                    print('order ', j, ' how much: ', order)\n",
    "            print()\n",
    "\n",
    "    print('Total number of rolls used: ', int(np.asarray(cut.ColumnSol_Val).sum()))\n",
    "##############\n",
    "\n",
    "\n",
    "class Episode(object):\n",
    "  def __init__(self, e_id:int = 0) -> None:\n",
    "      self.total_reward = 0  \n",
    "      self.trans_list = []    \n",
    "      self.name = str(e_id)   \n",
    "\n",
    "  def push(self, trans:Transition) -> float:\n",
    "      self.trans_list.append(trans)\n",
    "      self.total_reward += trans.reward \n",
    "      return self.total_reward\n",
    "\n",
    "  @property\n",
    "  def len(self):\n",
    "      return len(self.trans_list)\n",
    "\n",
    "  def __str__(self):\n",
    "      return \"episode {0:<4} {1:>4} steps,total reward:{2:<8.2f}\".\\\n",
    "          format(self.name, self.len, self.total_reward)\n",
    "\n",
    "  def print_detail(self):\n",
    "      print(\"detail of ({0}):\".format(self))\n",
    "      for i,trans in enumerate(self.trans_list):\n",
    "          print(\"step{0:<4} \".format(i),end=\" \")\n",
    "          print(trans)\n",
    "\n",
    "  def pop(self) -> Transition:\n",
    "      '''normally this method shouldn't be invoked.\n",
    "      '''\n",
    "      if self.len > 1:\n",
    "          trans = self.trans_list.pop()\n",
    "          self.total_reward -= trans.reward\n",
    "          return trans\n",
    "      else:\n",
    "          return None\n",
    "\n",
    "  def is_complete(self) -> bool:\n",
    "      '''check if an episode is an complete episode\n",
    "      '''\n",
    "      if self.len == 0: \n",
    "          return False \n",
    "      return self.trans_list[self.len-1].is_done\n",
    "\n",
    "  def sample(self, batch_size = 1):   \n",
    "      '''随即产生一个trans\n",
    "      '''\n",
    "      return random.sample(self.trans_list, k = batch_size)\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "      return self.len\n",
    "\n",
    "\n",
    "class Experience(object):\n",
    "  '''this class is used to record the whole experience of an agent organized\n",
    "  by an episode list. agent can randomly sample transitions or episodes from\n",
    "  its experience.\n",
    "  '''\n",
    "  def __init__(self, capacity:int = 20000):\n",
    "      self.capacity = capacity    \n",
    "      self.episodes = []         \n",
    "      self.next_id = 0            \n",
    "      self.total_trans = 0        \n",
    "      \n",
    "  def __str__(self):\n",
    "      return \"exp info:{0:5} episodes, memory usage {1}/{2}\".\\\n",
    "              format(self.len, self.total_trans, self.capacity)\n",
    "\n",
    "  def __len__(self):\n",
    "      return self.len\n",
    "\n",
    "  @property\n",
    "  def len(self):\n",
    "      return len(self.episodes)\n",
    "\n",
    "  def _remove(self, index = 0):      \n",
    "      '''\n",
    "          remove an episode, defautly the first one.\n",
    "          args: \n",
    "              the index of the episode to remove\n",
    "          return:\n",
    "              if exists return the episode else return None\n",
    "      '''\n",
    "      if index > self.len - 1:\n",
    "          raise(Exception(\"invalid index\"))\n",
    "      if self.len > 0:\n",
    "          episode = self.episodes[index]\n",
    "          self.episodes.remove(episode)\n",
    "          self.total_trans -= episode.len\n",
    "          return episode\n",
    "      else:\n",
    "          return None\n",
    "\n",
    "  def _remove_first(self):\n",
    "      self._remove(index = 0)\n",
    "\n",
    "  def push(self, trans): \n",
    "\n",
    "      if self.capacity <= 0:\n",
    "          return\n",
    "      while self.total_trans >= self.capacity: \n",
    "          episode = self._remove_first()\n",
    "      cur_episode = None\n",
    "      if self.len == 0 or self.episodes[self.len-1].is_complete():\n",
    "          cur_episode = Episode(self.next_id)\n",
    "          self.next_id += 1\n",
    "          self.episodes.append(cur_episode)\n",
    "      else:\n",
    "          cur_episode = self.episodes[self.len-1]\n",
    "      self.total_trans += 1\n",
    "      return cur_episode.push(trans)      #return  total reward of an episode\n",
    "\n",
    "  def sample(self, batch_size=32): # sample transition\n",
    "      '''randomly sample some transitions from agent's experience.abs\n",
    "      args:\n",
    "          number of transitions need to be sampled\n",
    "      return:\n",
    "          list of Transition.\n",
    "      '''\n",
    "      # sample_trans = []\n",
    "      sample_trans = np.asarray([])\n",
    "      for _ in range(batch_size):\n",
    "          index = int(random.random() * self.len)\n",
    "          sample_trans = np.append(sample_trans,self.episodes[index].sample())\n",
    "\n",
    "          # sample_trans += self.episodes[index].sample()\n",
    "      return sample_trans\n",
    "\n",
    "  def sample_episode(self, episode_num = 1):  # sample episode\n",
    "      '''\n",
    "      '''\n",
    "      return random.sample(self.episodes, k = episode_num)\n",
    "\n",
    "  @property\n",
    "  def last_episode(self):\n",
    "      if self.len > 0:\n",
    "          return self.episodes[self.len-1]\n",
    "      return None\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcASXobfVl6c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sys import exit\n",
    "import os\n",
    "\n",
    "\n",
    "def readInstanceN():\n",
    "    # Take in input instance name\n",
    "    print(\"Instance name: [r|c|rc][NNN]\")\n",
    "    INSTANCE_NAME = None\n",
    "    try:\n",
    "        INSTANCE_NAME = input()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid instance. Exit.\"); exit(1)\n",
    "    if INSTANCE_NAME.endswith(\".txt\"):\n",
    "        INSTANCE_NAME = INSTANCE_NAME[:-4]\n",
    "    INSTANCE_FILENAME = os.path.join(\"solomon-instances\", INSTANCE_NAME+\".txt\")\n",
    "    if not INSTANCE_NAME or not os.path.exists(INSTANCE_FILENAME):\n",
    "        print(\"Instance does not exists. Exit.\"); exit(1)\n",
    "\n",
    "    # Take in input customers number\n",
    "    print(\"Select number of costumers (1-100):\")\n",
    "    n = None\n",
    "    try:\n",
    "        n = int(input())\n",
    "    except Exception as e:\n",
    "        print(\"Invalid number of costumers. Exit.\"); exit(1)\n",
    "    if not n or n < 1 or n > 100:\n",
    "        print(\"Invalid number of costumers. Exit.\"); exit(1)\n",
    "    return INSTANCE_NAME, INSTANCE_FILENAME, n\n",
    "\n",
    "\n",
    "def readData(filename, n):\n",
    "    stream = \"\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        stream = file.readlines()\n",
    "    if stream == \"\":\n",
    "        print(\"Error in reading file\")\n",
    "    else:\n",
    "        print(\"Read file\", filename)\n",
    "\n",
    "    vehicleNumber, capacity = [int(i) for i in stream[4].split()]\n",
    "    fields = (\"CUST-NO.\", \"XCOORD.\", \"YCOORD.\", \"DEMAND\", \"READY-TIME\", \\\n",
    "                \"DUE-DATE\", \"SERVICE-TIME\")\n",
    "    data = list()\n",
    "    for i in range(9, len(stream)):\n",
    "        if stream[i] == \"\\n\":\n",
    "            continue\n",
    "        val = stream[i].split()\n",
    "        if len(val) != len(fields):\n",
    "            print(\"Error in reading data\")\n",
    "            continue\n",
    "        customer = dict(zip(fields, val))\n",
    "        data.append(customer)\n",
    "\n",
    "    # Consider only depot + 50 customers\n",
    "    data = data[0:n+1]\n",
    "    data.append(data[0]) # The depot is represented by two identical\n",
    "                         # nodes: 0 and n+1\n",
    "    data[-1][\"CUST-NO.\"] = \"51\"\n",
    "    x = []; y = []; q = []; a = []; b = []\n",
    "    for customer in data:\n",
    "        x.append(int(customer[\"XCOORD.\"]))\n",
    "        y.append(int(customer[\"YCOORD.\"]))\n",
    "        q.append(int(customer[\"DEMAND\"]))\n",
    "        a.append(int(customer[\"READY-TIME\"]))\n",
    "        b.append(int(customer[\"DUE-DATE\"]))\n",
    "\n",
    "    return vehicleNumber, capacity, x, y, q, a, b\n",
    "\n",
    "\n",
    "def createDistanceMatrix(x, y):\n",
    "    n = len(x)\n",
    "    d = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            p1 = np.array([x[i], y[i]])\n",
    "            p2 = np.array([x[j], y[j]])\n",
    "            d[i,j] = d[j,i] = int(round(np.linalg.norm(p1-p2)))\n",
    "    return d\n",
    "\n",
    "\n",
    "def addRoutesToMaster(routes, mat, costs, d):\n",
    "    for i in range(len(routes)):\n",
    "        cost = d[routes[i][0],routes[i][1]]\n",
    "        for j in range(1,len(routes[i])-1):\n",
    "            cost += d[routes[i][j], routes[i][j+1]]\n",
    "            mat[routes[i][j]-1,i] += 1\n",
    "        costs[i] = cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WBC1LxhYy2z"
   },
   "outputs": [],
   "source": [
    "b1 = b2 = b3 = bs = be = br = 1/3\n",
    "\n",
    "\n",
    "def insertNode(route, node, position, s, arr, d, a):\n",
    "    newRoute = route[:]\n",
    "    newRoute.insert(position, node)\n",
    "    newS = []; newArr = []\n",
    "    for i in range(position):\n",
    "        newS.append(s[i])\n",
    "        newArr.append(arr[i])\n",
    "    for i in range(position, len(newRoute)):\n",
    "        newArr.append(newS[i-1] + d[newRoute[i-1], newRoute[i]])\n",
    "        newS.append(max(newArr[i], a[i]))\n",
    "    return newRoute, newS, newArr\n",
    "\n",
    "\n",
    "def routeIsFeasible(route, a, b, s, d, q, Q):\n",
    "    cap = sum([q[node] for node in route])\n",
    "    if cap > Q:\n",
    "        return False\n",
    "    for i in range(len(route)):\n",
    "        if not ((s[i] >= a[route[i]]) and (s[i] <= b[route[i]])):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def computeISIULD(posU, route, arr, s, a, b, d, Jminu):\n",
    "    u = route[posU]\n",
    "    posI = posU-1; posJ = posU+1\n",
    "    i = route[posI]; j = route[posJ]\n",
    "    IS = arr[posU] - a[u]\n",
    "    IU = 1/(max([len(Jminu), 1])) * sum([max([b[n]-a[u]-d[u,n], b[u]-a[n]-d[u,n]]) \\\n",
    "                                for n in Jminu])\n",
    "    c1 = (d[i,u] + d[u,j] - d[i,j])\n",
    "    c2 = ((b[j]- (arr[posI] + d[i,j])) - \\\n",
    "                (b[j] - (arr[posU] + d[i,j])))\n",
    "    c3 = (b[u] - (arr[posI] + d[i,u]))\n",
    "    LD = b1*c1 + b2*c2 + b3*c3\n",
    "\n",
    "    return IS, IU, LD\n",
    "\n",
    "\n",
    "def computeImpact(IS, IU, LD, feasiblePositions):\n",
    "    IR = sum(LD)/len(feasiblePositions)\n",
    "    bestImpact = None\n",
    "    bestPosition = None\n",
    "    for i in range(len(feasiblePositions)):\n",
    "        impact = IS[i] + IU[i] + IR\n",
    "        if bestPosition == None or impact < bestImpact:\n",
    "            bestImpact = impact\n",
    "            bestPosition = feasiblePositions[i]\n",
    "\n",
    "    return bestPosition, bestImpact\n",
    "\n",
    "\n",
    "def computeRouteCost(route, d):\n",
    "    cost = 0\n",
    "    for i in range(len(route)-1):\n",
    "        cost += d[route[i], route[i+1]]\n",
    "    return cost\n",
    "\n",
    "\n",
    "def initializePathsWithImpact(d, n, a, b, q, Q):\n",
    "    J = list(range(1,n+1))\n",
    "    routes = []\n",
    "    costs = []\n",
    "\n",
    "    while J:\n",
    "        # Find furthest node from depot in J and initialize route with it\n",
    "        far = -1\n",
    "        max_dist = -1\n",
    "        for j in J:\n",
    "            if d[0,j] > max_dist:\n",
    "                far = j\n",
    "                max_dist = d[0,j]\n",
    "\n",
    "        route = [0, far, n+1]\n",
    "        arr = [0, d[0,far]]\n",
    "        s = [0, max([a[far], arr[1]])]\n",
    "        arr.append(s[1] + d[far,n+1])\n",
    "        s.append(max(arr[2], a[n+1]))\n",
    "        J.remove(far)\n",
    "\n",
    "        feasible = J[:]\n",
    "\n",
    "        while feasible:\n",
    "            proposals = dict()\n",
    "            for u in feasible:\n",
    "                bestImpact = None\n",
    "                bestPosition = None\n",
    "                Jminu = J[:]\n",
    "                Jminu.remove(u)\n",
    "                feasiblePositions = []\n",
    "                IS = IU = LD = []\n",
    "                for pos in range(1, len(route)):\n",
    "                    newRoute, newS, newArr = insertNode(route, u, pos, s, \\\n",
    "                                                        arr, d, a)\n",
    "                    if routeIsFeasible(newRoute, a, b, newS, d, q, Q):\n",
    "                        feasiblePositions.append(pos)\n",
    "                        Is, Iu, Ld = computeISIULD(pos, newRoute, newArr, \\\n",
    "                                                    newS, a, b, d, Jminu)\n",
    "                        IS.append(Is); IU.append(Iu); LD.append(Ld)\n",
    "\n",
    "                if not feasiblePositions:\n",
    "                    feasible.remove(u)\n",
    "                else:\n",
    "                    bestPosition, bestImpact = computeImpact(IS, IU, LD, \\\n",
    "                                                             feasiblePositions)\n",
    "                    proposals[bestImpact] = (u, bestPosition)\n",
    "                # END FOR\n",
    "            # prendo miglior impact\n",
    "            if proposals:\n",
    "                nodeToInsert, insertPos = proposals[min(list(proposals.keys()))]\n",
    "                # aggiungo nodo in posizione\n",
    "                route, s, arr = insertNode(route, nodeToInsert, insertPos, s, \\\n",
    "                                            arr, d, a)\n",
    "                # rimuovo nodo da J e da feasible\n",
    "                feasible.remove(nodeToInsert)\n",
    "                J.remove(nodeToInsert)\n",
    "            # END WHILE\n",
    "\n",
    "        routes.append(route)\n",
    "        costs.append(computeRouteCost(route, d))\n",
    "        # END WHILE\n",
    "    # print(\"Impact routes:\\n\", routes)\n",
    "    return routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICYisNTQYzQp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "import math\n",
    "\n",
    "\n",
    "def createMasterProblem(A, costs, n, vehicleNumber):\n",
    "    model = gp.Model(\"Master problem\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    y = model.addMVar(shape=A.shape[1], vtype=gp.GRB.CONTINUOUS, name=\"y\")\n",
    "    model.setObjective(costs @ y, gp.GRB.MINIMIZE)\n",
    "    # Constraints\n",
    "    model.addConstr(A @ y == np.ones(A.shape[0]))\n",
    "    model.write(\"MasterModel.lp\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def reduceTimeWindows(n, d, readyt, duedate):\n",
    "    a = readyt[:]; b = duedate[:]\n",
    "    update = True\n",
    "    while update:\n",
    "        update = False\n",
    "        for k in range(1,n+1):\n",
    "            # Ready Time\n",
    "            minArrPred = min([b[k], \\\n",
    "                            min([a[i] + d[i,k] for i in range(n+1) if i!=k])])\n",
    "            minArrNext = min([b[k], \\\n",
    "                            min([a[j] - d[k,j] for j in range(1,n+2) if j!=k])])\n",
    "            newa = int(max([a[k], minArrPred, minArrNext]))\n",
    "            if newa != a[k]:\n",
    "                update = True\n",
    "            a[k] = newa\n",
    "\n",
    "            # Due date\n",
    "            maxDepPred = max([a[k],\n",
    "                            max([b[i] + d[i,k] for i in range(n+1) if i!=k])])\n",
    "            maxDepNext = max([a[k],\n",
    "                            max([b[j] - d[k,j] for j in range(1,n+2) if j!=k])])\n",
    "            newb = int(min([b[k], maxDepPred, maxDepNext]))\n",
    "            if newb != b[k]:\n",
    "                update = True\n",
    "            b[k] = newb\n",
    "    return a,b\n",
    "\n",
    "\n",
    "def subProblem(n, q, d, readyt, duedate, rc, Q):\n",
    "    \n",
    "    M = gp.GRB.INFINITY     # 1e+100\n",
    "    # Time windows reduction\n",
    "    a,b = reduceTimeWindows(n, d, readyt, duedate)\n",
    "    # Reduce max capacity to boost algorithm\n",
    "    if sum(q) < Q:\n",
    "        Q = sum(q)\n",
    "    T = max(b)\n",
    "\n",
    "    # Init necessary data structure\n",
    "    f = list()  # paths cost data struct\n",
    "    p = list()  # paths predecessor data struct\n",
    "    f_tk = list()     # cost of the best path that does not pass for\n",
    "                      # predecessor (we'll call it alternative path)\n",
    "    paths = []\n",
    "    paths_tk = []\n",
    "    for j in range(n+2):\n",
    "        paths.append([])\n",
    "        paths_tk.append([])\n",
    "        for qt in range(Q-q[j]):\n",
    "            paths[-1].append([])\n",
    "            paths_tk[-1].append([])\n",
    "            for tm in range(b[j]-a[j]):\n",
    "                paths[-1][-1].append([])\n",
    "                paths_tk[-1][-1].append([])\n",
    "        mat = np.zeros((Q-q[j], b[j] - a[j]))\n",
    "        p.append(mat - 1)\n",
    "        f.append(mat + M)\n",
    "        f_tk.append(mat + M)\n",
    "    f[0][0,0] = 0\n",
    "    f_tk[0][0,0] = 0\n",
    "    L = set()   # Node to explore\n",
    "    L.add(0)\n",
    "\n",
    "    # Algorithm\n",
    "\n",
    "\n",
    "\n",
    "    while L:\n",
    "        \n",
    "\n",
    "        i = L.pop()\n",
    "        if i == n+1:\n",
    "            continue\n",
    "\n",
    "        # Explore all possible arcs (i,j)\n",
    "        for j in range(1,n+2):\n",
    "            if i == j:\n",
    "                continue\n",
    "            for q_tk in range(q[i], Q-q[j]):\n",
    "                for t_tk in range(a[i], b[i]):\n",
    "                    if p[i][q_tk-q[i], t_tk-a[i]] != j:\n",
    "                        if f[i][q_tk-q[i], t_tk-a[i]] < M:\n",
    "                            for t in range(max([a[j], int(t_tk+d[i,j])]),\\\n",
    "                                                b[j]):\n",
    "                                if f[j][q_tk, t-a[j]]> \\\n",
    "                                   f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                    # if the current best path is suitable to\n",
    "                                    # become the alternative path\n",
    "                                    if p[j][q_tk, t-a[j]] != i \\\n",
    "                                       and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                       and f[j][q_tk, t-a[j]] < M \\\n",
    "                                       and f[j][q_tk,t-a[j]]<f_tk[j][q_tk,t-a[j]]:\n",
    "                                        f_tk[j][q_tk,t-a[j]] = f[j][q_tk,t-a[j]]\n",
    "                                        paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                                paths[j][q_tk][t-a[j]][:]\n",
    "                                    # update f\n",
    "                                    f[j][q_tk,t-a[j]] = \\\n",
    "                                            f[i][q_tk-q[i],t_tk-a[i]] + rc[i,j]\n",
    "                                    # update path that leads to node j\n",
    "                                    paths[j][q_tk][t-a[j]] = \\\n",
    "                                            paths[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "                                    # Update predecessor\n",
    "                                    p[j][q_tk, t-a[j]] = i\n",
    "                                    L.add(j)\n",
    "                                # if the path is suitable to be the alternative\n",
    "                                elif p[j][q_tk, t-a[j]] != i \\\n",
    "                                    and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                    and f_tk[j][q_tk, t-a[j]] > \\\n",
    "                                            f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                    f_tk[j][q_tk,t-a[j]] = \\\n",
    "                                            f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]\n",
    "                                    paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                            paths[i][q_tk-q[i]][t_tk-a[i]]+[j]\n",
    "                    else:       # if predecessor of i is j\n",
    "                        if f_tk[i][q_tk-q[i], t_tk-a[i]] < M:\n",
    "                            for t in range(max([a[j],int(t_tk+d[i,j])]), \\\n",
    "                                                b[j]):\n",
    "                                if f[j][q_tk,t-a[j]] > \\\n",
    "                                        f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                    # if the current best path is suitable to\n",
    "                                    # become the alternative path\n",
    "                                    if p[j][q_tk, t-a[j]] != i \\\n",
    "                                        and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                        and f[j][q_tk, t-a[j]] < M \\\n",
    "                                        and f[j][q_tk,t-a[j]] < \\\n",
    "                                                f_tk[j][q_tk,t-a[j]]:\n",
    "                                        f_tk[j][q_tk,t-a[j]] = f[j][q_tk,t-a[j]]\n",
    "                                        paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                                paths[j][q_tk][t-a[j]][:]\n",
    "                                    # update f, path and bucket\n",
    "                                    f[j][q_tk,t-a[j]] = \\\n",
    "                                        f_tk[i][q_tk-q[i],t_tk-a[i]] + rc[i,j]\n",
    "                                    paths[j][q_tk][t-a[j]] = \\\n",
    "                                        paths_tk[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "                                    p[j][q_tk,t-a[j]] = i\n",
    "                                    L.add(j)\n",
    "                                # if the alternative path of i is suitable to\n",
    "                                # be the alternate of j\n",
    "                                elif p[j][q_tk, t-a[j]] != i \\\n",
    "                                     and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                     and f_tk[j][q_tk,t-a[j]] > \\\n",
    "                                            f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                    f_tk[j][q_tk, t-a[j]] = \\\n",
    "                                        f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]\n",
    "                                    paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                        paths_tk[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "\n",
    "    # Return all the routes with negative cost\n",
    "    routes = list()\n",
    "    rcosts = list()\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    qBest, tBest = np.where(f[n+1] < -1e-9)\n",
    "\n",
    "\n",
    "    for i in range(len(qBest)):\n",
    "        newRoute = [0] + paths[n+1][qBest[i]][tBest[i]]\n",
    "        if not newRoute in routes:\n",
    "            routes.append(newRoute)\n",
    "            rcosts.append(f[n+1][qBest[i]][tBest[i]])\n",
    "    \n",
    "    print(\"total iteration is\", counter)\n",
    "    print(\"total len of routes generated is\", len(routes))\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbxfikcXY9DR"
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "from sys import exit\n",
    "\n",
    "\n",
    "def coverCostHeuristic(bestIndex, allRoutes, allCosts, allCoverCost):\n",
    "    nodes = set(range(1,n+1))\n",
    "    routes = allRoutes[:]\n",
    "    costs = allCosts[:]\n",
    "    coverCost = allCoverCost[:]\n",
    "\n",
    "    for node in routes[bestIndex][1:-1]:\n",
    "        nodes.remove(node)\n",
    "    sol = [routes[bestIndex]]\n",
    "    solCost = costs[bestIndex]\n",
    "\n",
    "    # Start loop\n",
    "    while nodes:\n",
    "        filteredRoutes = []\n",
    "        filteredCosts = []\n",
    "        filteredCoverCost = []\n",
    "        for i in range(len(routes)):\n",
    "            feasible = True\n",
    "            for node in routes[i][1:-1]:\n",
    "                if not node in nodes:\n",
    "                    feasible = False\n",
    "                    break\n",
    "            if feasible:\n",
    "                filteredRoutes.append(routes[i])\n",
    "                filteredCosts.append(costs[i])\n",
    "                filteredCoverCost.append(coverCost[i])\n",
    "        if not filteredRoutes:\n",
    "            return None\n",
    "\n",
    "        bestIdx = filteredCoverCost.index(max(filteredCoverCost))\n",
    "        sol.append(filteredRoutes[bestIdx])\n",
    "        solCost += filteredCosts[bestIdx]\n",
    "        for node in filteredRoutes[bestIdx][1:-1]:\n",
    "            nodes.remove(node)\n",
    "        routes = filteredRoutes[:]\n",
    "        costs = filteredCosts[:]\n",
    "\n",
    "    return (sol, solCost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laeSzM1EY6un"
   },
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def computeMaxCost(d, a, b, n):\n",
    "    # TODO: Use distance mat. to find an equivalent to infinity for subproblem\n",
    "    return max([b[i] + d[i,j] - a[j] for i in range(n+2) for j in range(n+2)])\n",
    "\n",
    "\n",
    "def setESPModelFO(model, x_vars, pi, n, d):\n",
    "    rc = np.zeros((n+2,n+2))\n",
    "    for i in range(n+2):\n",
    "        for j in range(n+2):\n",
    "            if (i==0) or (i==n+1):\n",
    "                rc[i,j] = d[i,j]\n",
    "            else:\n",
    "                rc[i,j] = d[i,j] - pi[i-1]\n",
    "    model.setObjective(gp.quicksum(x_vars[i,j]*rc[i,j] for i in range(n+2) \\\n",
    "                                                       for j in range(n+2)), \\\n",
    "                       gp.GRB.MINIMIZE)\n",
    "    return\n",
    "\n",
    "\n",
    "def createESPModel(d, pi, q, Q, a, b, n):\n",
    "    M = computeMaxCost(d, a, b, n)\n",
    "    model = gp.Model(\"ESPModel\")\n",
    "    x_vars = model.addVars(n+2, n+2, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "    s_vars = model.addVars(n+2, vtype=gp.GRB.CONTINUOUS, name=\"s\")\n",
    "\n",
    "    setESPModelFO(model, x_vars, pi, n, d)\n",
    "\n",
    "    # R0: capacity constraint\n",
    "    model.addConstr(sum([q[i] * \\\n",
    "                    gp.quicksum(x_vars[i,j] for j in range(n+2)) \\\n",
    "                    for i in range(1,n+1)]) <= Q)\n",
    "    # R1: depot start constraint\n",
    "    model.addConstr(gp.quicksum(x_vars[0,j] for j in range(n+2)) == 1)\n",
    "    # R2: depot finish constraint\n",
    "    model.addConstr(gp.quicksum(x_vars[i,n+1] for i in range(n+2)) == 1)\n",
    "    # R3-R53: flow costraints\n",
    "    for h in range(1,n+1):\n",
    "        model.addConstr(gp.quicksum(x_vars[i,h] for i in range(n+2)) - \\\n",
    "                        gp.quicksum(x_vars[h,j] for j in range(n+2)) == 0)\n",
    "\n",
    "    # Time windows contraints\n",
    "    for i in range(n+2):\n",
    "        for j in range(n+2):\n",
    "            if j!=i:\n",
    "                model.addConstr(s_vars[i] + d[i,j] - M*(1-x_vars[i,j]) <= \\\n",
    "                                s_vars[j])\n",
    "\n",
    "    # Service time constraints\n",
    "    model.addConstrs(s_vars[i] >= a[i] for i in range(1,n+1))\n",
    "    model.addConstrs(s_vars[i] <= b[i] for i in range(1,n+1))\n",
    "\n",
    "    # Goodsense constraints:\n",
    "    # Must not exist an arc that connects a customer with himself\n",
    "    model.addConstr(gp.quicksum(x_vars[i,i] for i in range(n+2)) == 0)\n",
    "    # No arc can enter in the first node\n",
    "    model.addConstr(gp.quicksum(x_vars[i,0] for i in range(n+2)) == 0)\n",
    "    # No arc can exit from the last node\n",
    "    model.addConstr(gp.quicksum(x_vars[n+1,j] for j in range(n+2)) == 0)\n",
    "\n",
    "    # model.write(\"ESPModel.lp\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lvX_wkMGukl"
   },
   "source": [
    "## The main difference between RLCG_VRP and RLCG_CSP is the environment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVzkmmEddDKf"
   },
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "import os\n",
    "from gurobipy import GRB\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class VRP(object):\n",
    "    def __init__(self, INSTANCE_NAME, n): ## input the name of that instance\n",
    "\n",
    "        # each instance corresponds to self.state = self.env.reset() in learning_method in agent.py\n",
    "\n",
    "        # state: curent graph (connection, current column nodes, current constraint node and their features)\n",
    "        #### static info: problem defination, same info used for initialization this instance\n",
    "\n",
    "        Kdim, Q, x, y, q, a, b = readData(INSTANCE_NAME, n)\n",
    "        \n",
    "        #### fixed info\n",
    "        self.n = n\n",
    "        self.Kdim = Kdim\n",
    "        self.Q = Q\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.q = q\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.d = createDistanceMatrix(x, y)\n",
    "\n",
    "\n",
    "        #### dynamic info for building RMP, PP\n",
    "\n",
    "\n",
    "        ## update by addRoutetoMaster\n",
    "        self.A = None ## like self.patterns as before\n",
    "        self.c = None   # routes costs\n",
    "\n",
    "        self.routes = None ## route list storing current routes\n",
    "        \n",
    "\n",
    "        #### dynamic info (info needed to for state + reward), get from CG iterations from solving current RMP and PP:  \n",
    "        self.objVal_history = []\n",
    "        self.total_steps = 0\n",
    "\n",
    "        ## action with their reduced cost (stored as tuple) ([all the patterns],[(data for those routes)])\n",
    "        self.available_action = ()\n",
    "\n",
    "   \n",
    "\n",
    "        self.count_convergence = 0\n",
    "\n",
    "        '''  \n",
    "        Info for column and constraint node features, stored using list,length will change\n",
    "            column \n",
    "                      number of constraint participation\n",
    "                      current solution value (if not in the basis, 0 -> int or not)\n",
    "                      columnIsNew\n",
    "\n",
    "                      column incompatibility degree --> check this\n",
    "\n",
    "             constraint : shadow price\n",
    "                          number of columns contributing to the constraint\n",
    "        '''  \n",
    "        ## for all the columns (size change)\n",
    "\n",
    "        # self.RC = [] #### don't quite know how rc works here, so what i will do is that i will only have rc value for actions, all other rc is 0 ? \n",
    "\n",
    "        self.In_Cons_Num = []\n",
    "        self.ColumnSol_Val = []\n",
    "        self.ColumnIs_Basic = []\n",
    "        \n",
    "        ## for all the variable that are in the basis, count the number of times it's in basis, otherwise 0\n",
    "        self.stay_in = []\n",
    "        self.stay_out = []\n",
    "        ## 1-> just left the basis in last iteration, 0 not just left\n",
    "        self.just_left = []\n",
    "        self.just_enter = []\n",
    "\n",
    "        ## 1-> is action node, 0 -> .. useless as we can do this at get_aug_state\n",
    "        # self.action_node = []\n",
    "\n",
    "\n",
    "\n",
    "        ## for all the constraints (size fixed)\n",
    "        self.Shadow_Price = None\n",
    "        self.In_Cols_Num = []\n",
    "\n",
    "\n",
    "\n",
    "    def generate_initial_patterns(self):\n",
    "\n",
    "        impactSol = initializePathsWithImpact(self.d, self.n, self.a, self.b, self.q, self.Q)\n",
    "        initial_routes = impactSol[:]\n",
    "        self.routes = deepcopy(initial_routes)\n",
    "\n",
    "        #print(\"Impact solution:\", routes)\n",
    "\n",
    "        # impactCost = sum([computeRouteCost(self.routes, self.d) for route in self.routes])\n",
    "\n",
    "\n",
    "        A = np.zeros((self.n, len(self.routes)))\n",
    "        c = np.zeros(len(self.routes))  \n",
    "        addRoutesToMaster(self.routes, A, c, self.d)\n",
    "\n",
    "        self.A = deepcopy(A)\n",
    "        self.c = deepcopy(c)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # get the constraint participation for each col node and col participation for each cons node\n",
    "    ## use current patterns to count the non-zeros in the pattern matrix\n",
    "\n",
    "    ### use A matrix -- read carefully how master and pp is built\n",
    "    def update_col_con_number(self):\n",
    "        A = deepcopy(self.A)\n",
    "        self.In_Cons_Num = np.count_nonzero(A, axis=0)\n",
    "        self.In_Cols_Num = np.count_nonzero(A, axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def createMasterProblem(self):\n",
    "        A = self.A\n",
    "        costs = self.c\n",
    "        n = self.n\n",
    "        vehicleNumber = self.Kdim\n",
    "\n",
    "        model = gp.Model(\"Master problem\")\n",
    "        model.Params.OutputFlag = 0\n",
    "        y = model.addMVar(shape=A.shape[1], vtype=gp.GRB.CONTINUOUS, name=\"y\")\n",
    "        model.setObjective(costs @ y, gp.GRB.MINIMIZE)\n",
    "        # Constraints\n",
    "        model.addConstr(A @ y == np.ones(A.shape[0]))\n",
    "        model.write(\"MasterModel.lp\")\n",
    "        model.Params.LogToConsole = 0\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    # def solve_subproblem_return_actions(self, duals):\n",
    "    # newRoutes = subProblem(n, q, d, a, b, rc, Q)\n",
    "\n",
    "    def solve_subproblem_return_actions(self, rc, test=False):\n",
    "       \n",
    "        n = self.n\n",
    "        q = self.q\n",
    "        d = self.d\n",
    "        readyt = self.a\n",
    "        duedate = self.b\n",
    "        Q = self.Q\n",
    "\n",
    "        M = gp.GRB.INFINITY     # 1e+100\n",
    "        # Time windows reduction\n",
    "        a,b = reduceTimeWindows(n, d, readyt, duedate)\n",
    "        # Reduce max capacity to boost algorithm\n",
    "        if sum(q) < Q:\n",
    "            Q = sum(q)\n",
    "        T = max(b)\n",
    "\n",
    "        # Init necessary data structure\n",
    "        f = list()  # paths cost data struct\n",
    "        p = list()  # paths predecessor data struct\n",
    "        f_tk = list()     # cost of the best path that does not pass for\n",
    "                          # predecessor (we'll call it alternative path)\n",
    "        paths = []\n",
    "        paths_tk = []\n",
    "        for j in range(n+2):\n",
    "            paths.append([])\n",
    "            paths_tk.append([])\n",
    "            for qt in range(Q-q[j]):\n",
    "                paths[-1].append([])\n",
    "                paths_tk[-1].append([])\n",
    "                for tm in range(b[j]-a[j]):\n",
    "                    paths[-1][-1].append([])\n",
    "                    paths_tk[-1][-1].append([])\n",
    "            mat = np.zeros((Q-q[j], b[j] - a[j]))\n",
    "            p.append(mat - 1)\n",
    "            f.append(mat + M)\n",
    "            f_tk.append(mat + M)\n",
    "        f[0][0,0] = 0\n",
    "        f_tk[0][0,0] = 0\n",
    "        L = set()   # Node to explore\n",
    "        L.add(0)\n",
    "\n",
    "        # Algorithm\n",
    "        computation_counter = 0\n",
    "        while L:\n",
    "            if test: ## we will test on large instances, so set up some computation limits\n",
    "                if computation_counter>=20:\n",
    "                    computation_counter +=1\n",
    "                    break\n",
    "            else:\n",
    "                computation_counter +=1 ## but for trainninng we want to train without such limits as instances are small\n",
    "            \n",
    "\n",
    "            i = L.pop()\n",
    "            if i == n+1:\n",
    "                continue\n",
    "\n",
    "            # Explore all possible arcs (i,j)\n",
    "            for j in range(1,n+2):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                for q_tk in range(q[i], Q-q[j]):\n",
    "                    for t_tk in range(a[i], b[i]):\n",
    "                        if p[i][q_tk-q[i], t_tk-a[i]] != j:\n",
    "                            if f[i][q_tk-q[i], t_tk-a[i]] < M:\n",
    "                                for t in range(max([a[j], int(t_tk+d[i,j])]),\\\n",
    "                                                    b[j]):\n",
    "                                    if f[j][q_tk, t-a[j]]> \\\n",
    "                                      f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                        # if the current best path is suitable to\n",
    "                                        # become the alternative path\n",
    "                                        if p[j][q_tk, t-a[j]] != i \\\n",
    "                                          and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                          and f[j][q_tk, t-a[j]] < M \\\n",
    "                                          and f[j][q_tk,t-a[j]]<f_tk[j][q_tk,t-a[j]]:\n",
    "                                            f_tk[j][q_tk,t-a[j]] = f[j][q_tk,t-a[j]]\n",
    "                                            paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                                    paths[j][q_tk][t-a[j]][:]\n",
    "                                        # update f\n",
    "                                        f[j][q_tk,t-a[j]] = \\\n",
    "                                                f[i][q_tk-q[i],t_tk-a[i]] + rc[i,j]\n",
    "                                        # update path that leads to node j\n",
    "                                        paths[j][q_tk][t-a[j]] = \\\n",
    "                                                paths[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "                                        # Update predecessor\n",
    "                                        p[j][q_tk, t-a[j]] = i\n",
    "                                        L.add(j)\n",
    "                                    # if the path is suitable to be the alternative\n",
    "                                    elif p[j][q_tk, t-a[j]] != i \\\n",
    "                                        and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                        and f_tk[j][q_tk, t-a[j]] > \\\n",
    "                                                f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                        f_tk[j][q_tk,t-a[j]] = \\\n",
    "                                                f[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]\n",
    "                                        paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                                paths[i][q_tk-q[i]][t_tk-a[i]]+[j]\n",
    "                        else:       # if predecessor of i is j\n",
    "                            if f_tk[i][q_tk-q[i], t_tk-a[i]] < M:\n",
    "                                for t in range(max([a[j],int(t_tk+d[i,j])]), \\\n",
    "                                                    b[j]):\n",
    "                                    if f[j][q_tk,t-a[j]] > \\\n",
    "                                            f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                        # if the current best path is suitable to\n",
    "                                        # become the alternative path\n",
    "                                        if p[j][q_tk, t-a[j]] != i \\\n",
    "                                            and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                            and f[j][q_tk, t-a[j]] < M \\\n",
    "                                            and f[j][q_tk,t-a[j]] < \\\n",
    "                                                    f_tk[j][q_tk,t-a[j]]:\n",
    "                                            f_tk[j][q_tk,t-a[j]] = f[j][q_tk,t-a[j]]\n",
    "                                            paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                                    paths[j][q_tk][t-a[j]][:]\n",
    "                                        # update f, path and bucket\n",
    "                                        f[j][q_tk,t-a[j]] = \\\n",
    "                                            f_tk[i][q_tk-q[i],t_tk-a[i]] + rc[i,j]\n",
    "                                        paths[j][q_tk][t-a[j]] = \\\n",
    "                                            paths_tk[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "                                        p[j][q_tk,t-a[j]] = i\n",
    "                                        L.add(j)\n",
    "                                    # if the alternative path of i is suitable to\n",
    "                                    # be the alternate of j\n",
    "                                    elif p[j][q_tk, t-a[j]] != i \\\n",
    "                                        and p[j][q_tk, t-a[j]] != -1 \\\n",
    "                                        and f_tk[j][q_tk,t-a[j]] > \\\n",
    "                                                f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]:\n",
    "                                        f_tk[j][q_tk, t-a[j]] = \\\n",
    "                                            f_tk[i][q_tk-q[i],t_tk-a[i]]+rc[i,j]\n",
    "                                        paths_tk[j][q_tk][t-a[j]] = \\\n",
    "                                            paths_tk[i][q_tk-q[i]][t_tk-a[i]] + [j]\n",
    "\n",
    "        # Return all the routes with negative cost\n",
    "        routes = list()\n",
    "        rcosts = list()\n",
    "        qBest, tBest = np.where(f[n+1] < -1e-9)\n",
    "\n",
    "        for i in range(len(qBest)):\n",
    "            newRoute = [0] + paths[n+1][qBest[i]][tBest[i]]\n",
    "            if not newRoute in routes:\n",
    "                routes.append(newRoute)\n",
    "                rcosts.append(f[n+1][qBest[i]][tBest[i]])\n",
    "\n",
    "        # print(\"New routes:\", routes, flush=True)\n",
    "\n",
    "\n",
    "        # print(\"reduced cost?\", rcosts)\n",
    "\n",
    "\n",
    "        costs = np.zeros(len(routes))\n",
    "        for i in range(len(routes)):\n",
    "            cost = d[routes[i][0],routes[i][1]]\n",
    "            for j in range(1,len(routes[i])-1):\n",
    "                cost += d[routes[i][j], routes[i][j+1]]\n",
    "            costs[i] = cost\n",
    "\n",
    "        costs = list(costs)\n",
    "        # print(\"new routes\",routes)\n",
    "\n",
    "\n",
    "        return routes,rcosts,costs  ## return all avaliable actions (new routes generated, called routes here) and their rc\n",
    "\n",
    "        \n",
    "\n",
    "    def initialize(self,test_or_not=False):\n",
    "\n",
    "        self.generate_initial_patterns()\n",
    "        self.total_steps = 0\n",
    "        routes = self.routes\n",
    "\n",
    "        self.update_col_con_number()\n",
    "\n",
    "        master_problem = self.createMasterProblem()\n",
    "        master_problem.optimize()\n",
    "\n",
    "        # # Compute reduced costs\n",
    "        # constr = masterModel.getConstrs()\n",
    "        # pi_i = [0.] + [const.pi for const in constr] + [0.]\n",
    "        # for i in range(n+2):\n",
    "        #     for j in range(n+2):\n",
    "        #         rc[i,j] = d[i,j] - pi_i[i]\n",
    "\n",
    "        # if not np.where(rc < -1e-9):\n",
    "        #     break\n",
    "\n",
    "        # self.RC = np.zeros(len(self.routes))\n",
    "\n",
    "\n",
    "        self.ColumnSol_Val = np.asarray(master_problem.x)\n",
    "        self.ColumnIs_Basic = np.asarray(master_problem.vbasis)+np.ones(len(routes))\n",
    "        self.objVal_history.append(master_problem.objVal)\n",
    "\n",
    "\n",
    "        dual_variables = [constraint.pi for constraint in master_problem.getConstrs()]\n",
    "        self.Shadow_Price = dual_variables\n",
    "\n",
    "        # Compute reduced costs\n",
    "        constr = master_problem.getConstrs()\n",
    "        pi_i = [0.] + [const.pi for const in constr] + [0.]\n",
    "\n",
    "        rc = np.zeros((self.n+2,self.n+2))\n",
    "        for i in range(self.n+2):\n",
    "            for j in range(self.n+2):\n",
    "                rc[i,j] = self.d[i,j] - pi_i[i]\n",
    "        # print(\"reduced cost\",rc)\n",
    "\n",
    "\n",
    "        too_long = False\n",
    "        time_before = time.time()\n",
    "        columns_to_select,reduced_costs,route_costs = self.solve_subproblem_return_actions(rc,test_or_not)\n",
    "        time_after = time.time()\n",
    "        \n",
    "        if not test:\n",
    "            if time_after - time_before >=100.0: ## if the instance takes too long to solve during training, skip it\n",
    "                too_long = True\n",
    "        else:\n",
    "            too_long = False ## test every instances\n",
    "\n",
    "        self.available_action = (columns_to_select,[reduced_costs,route_costs])\n",
    "\n",
    "\n",
    "        self.stay_in = list(np.zeros(len(routes)))\n",
    "        self.stay_out = list(np.zeros(len(routes)))\n",
    "        self.just_left = list(np.zeros(len(routes)))\n",
    "        self.just_enter = list(np.zeros(len(routes)))\n",
    "\n",
    "        reward = 0\n",
    "        is_done = False\n",
    "  \n",
    "        return reward, is_done,too_long\n",
    "        \n",
    "\n",
    "    def step(self,action,test_or_not=False):\n",
    "        self.total_steps +=1\n",
    "        is_done = False\n",
    "\n",
    "        ## historical info\n",
    "        last_columns_to_select, columns_info = deepcopy(self.available_action) \n",
    "        last_basis= deepcopy(self.ColumnIs_Basic[:])\n",
    "        last_basis = np.append(last_basis,0)\n",
    "\n",
    "\n",
    "        self.routes.append(action)\n",
    "        idx = 0\n",
    "        for one_act in last_columns_to_select:\n",
    "            if one_act == action:\n",
    "                break\n",
    "            idx+=1\n",
    "        \n",
    "        routes = deepcopy(self.routes)\n",
    "\n",
    "        ## just append one cost\n",
    "        self.c = np.append(self.c,columns_info[1][idx])\n",
    "\n",
    "        ########################################\n",
    "        # self.rc.appennd(columns_info[0][idx])\n",
    "        ########################################\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # c = np.zeros(len(self.routes))  \n",
    "        # addRoutesToMaster(self.routes, A, c, self.d)\n",
    "\n",
    "\n",
    "\n",
    "        add_A = np.zeros((self.n, 1))\n",
    "\n",
    "        for j in range(1,len(action)-1):\n",
    "            add_A[action[j]-1] += 1\n",
    "\n",
    "        # print(add_A)\n",
    "        self.A = np.c_[self.A, add_A]\n",
    "\n",
    "        self.update_col_con_number()\n",
    "\n",
    "        master_problem = self.createMasterProblem()\n",
    "        master_problem.optimize()\n",
    "\n",
    "        dual_variables = [constraint.pi for constraint in master_problem.getConstrs()]\n",
    "        self.Shadow_Price = dual_variables\n",
    "\n",
    "        self.ColumnSol_Val = np.asarray(master_problem.x)\n",
    "        self.ColumnIs_Basic = np.asarray(master_problem.vbasis)+np.ones(len(routes))\n",
    "\n",
    "        #### you can either stay in the basis, leave the basis, or enter the basis\n",
    "        difference = last_basis - self.ColumnIs_Basic \n",
    "\n",
    "        ### update the dynamic basis info based on difference\n",
    "        self.just_left = list(np.zeros(len(difference)-1))\n",
    "        self.just_enter = list(np.zeros(len(difference)-1))\n",
    "        for i in range(len(difference)-1):\n",
    "            if difference[i] == 1:\n",
    "                \n",
    "                self.just_left[i] = 1\n",
    "                self.stay_in[i] = 0\n",
    "            elif difference[i] == -1:\n",
    "                \n",
    "                self.just_enter[i] = 1\n",
    "                self.stay_out[i] = 0\n",
    "            elif difference[i] == 0:\n",
    "                if last_basis[i] == 1:\n",
    "                    self.stay_in[i]+=1\n",
    "                else:\n",
    "                    self.stay_out[i]+=1\n",
    "\n",
    "        # append info for the new node; for just enter, look at column is basic\n",
    "        self.just_left.append(0)\n",
    "        self.stay_out.append(0)\n",
    "        self.stay_in.append(0)\n",
    "\n",
    "        if self.ColumnIs_Basic[-1] == 1:\n",
    "            self.just_enter.append(1)\n",
    "        else:\n",
    "            self.just_enter.append(0)\n",
    "   \n",
    "        self.objVal_history.append(master_problem.objVal)\n",
    "\n",
    "\n",
    "\n",
    "        rc = np.zeros((self.n+2,self.n+2))\n",
    "\n",
    "        # Compute (rc, don't know what it is) used for building subproblem\n",
    "        constr = master_problem.getConstrs()\n",
    "        pi_i = [0.] + [const.pi for const in constr] + [0.]\n",
    "        for i in range(self.n+2):\n",
    "            for j in range(self.n+2):\n",
    "                rc[i,j] = self.d[i,j] - pi_i[i]\n",
    "        # print(\"reduced cost\",rc)\n",
    "\n",
    "\n",
    "        new_routes,action_rcosts,action_costs = self.solve_subproblem_return_actions(rc,test_or_not)\n",
    "        if new_routes == []:\n",
    "            is_done = True\n",
    "            reward = 0.5*(self.objVal_history[-1] - self.objVal_history[0])\n",
    "\n",
    "        else:\n",
    "            self.available_action = (new_routes,[action_rcosts,action_costs])\n",
    "#             reward = 100*(self.objVal_history[-2] - self.objVal_history[-1])/self.objVal_history[0] ## normalization term\n",
    "        reward -=1\n",
    "\n",
    "\n",
    "\n",
    "        return reward, is_done\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmMTSRuL3Axq"
   },
   "source": [
    "## Now for the learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzT0zfTZ6rns"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent(object):\n",
    "  '''Base Class of Agent\n",
    "  '''\n",
    "  def __init__(self, initial_env=None, capacity = 10000):\n",
    "      self.env = initial_env # the evironment would be one cutting stock object\n",
    "      ## add the env and available action will be added in the learning_method \n",
    "      # self.A = self.env.available_action\n",
    "\n",
    "      self.A = []\n",
    "      self.experience = Experience(capacity = capacity)\n",
    "      # S record the current super state for the agent\n",
    "      # self.S = self.get_aug_state()   \n",
    "\n",
    "      self.S = []\n",
    "\n",
    "\n",
    "  ## get augmented state from the current environment\n",
    "  def get_aug_state(self):\n",
    "\n",
    "      \n",
    "      # actions,reduced_costs = deepcopy(self.env.available_action)\n",
    "\n",
    "      # print(self.env.A)\n",
    "\n",
    "      actions,action_info = deepcopy(self.env.available_action)\n",
    "      reduced_costs = action_info[0]\n",
    "      \n",
    "      total_added = len(actions)\n",
    "\n",
    "      patterns = self.env.routes[:]\n",
    "\n",
    "      is_action = np.asarray([0]*len(patterns))\n",
    "\n",
    "      patterns.extend(actions)\n",
    "\n",
    "\n",
    "\n",
    "      col_num = len(patterns)\n",
    "      cons_num = self.env.n\n",
    "      column_features = []\n",
    "      cons_features = []\n",
    "      edge_indices = [[],[]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # RC = self.env.RC[:]\n",
    "      # RC = np.append(RC,reduced_costs)\n",
    "\n",
    "\n",
    "      \n",
    "      ###################################################\n",
    "      MatA = deepcopy(self.env.A)\n",
    "      cost_c = deepcopy(self.env.c)\n",
    "\n",
    "      newMat = np.zeros((self.env.n, len(actions)))\n",
    "      newCosts = np.zeros(len(actions))\n",
    "      addRoutesToMaster(actions, newMat, newCosts, self.env.d) \n",
    "\n",
    "      # routes += newRoutes\n",
    "      MatA = np.c_[MatA, newMat]\n",
    "\n",
    "      In_Cons_Num = np.count_nonzero(MatA, axis=0)\n",
    "      ###################################################\n",
    "\n",
    "\n",
    "      ColumnSol_Val = self.env.ColumnSol_Val[:]\n",
    "      ColumnSol_Val = np.append(ColumnSol_Val, np.zeros(total_added))\n",
    "      cost_c = np.append(cost_c, newCosts)\n",
    "\n",
    "      stay_in = self.env.stay_in[:]\n",
    "      stay_in = np.append(stay_in,np.zeros(total_added))\n",
    "      stay_out = self.env.stay_out[:]\n",
    "      stay_out = np.append(stay_out,np.zeros(total_added))\n",
    "      just_left = self.env.just_left[:]\n",
    "      just_left = np.append(just_left,np.zeros(total_added))\n",
    "      just_enter = self.env.just_enter[:]\n",
    "      just_enter = np.append(just_enter,np.zeros(total_added))\n",
    "\n",
    "      is_action = np.append(is_action,np.ones(total_added))\n",
    "      \n",
    "\n",
    "\n",
    "      #### constraint features, also augment all actions\n",
    "      Shadow_Price = self.env.Shadow_Price[:]\n",
    "      In_Cols_Num = np.count_nonzero(MatA, axis=1)\n",
    "\n",
    "      # In_Cols_Num = self.env.In_Cols_Num[:]\n",
    "      # for action in actions:\n",
    "      #     non_zero = np.nonzero(action)\n",
    "      #     for idx in non_zero:\n",
    "      #         In_Cols_Num[idx]+=1\n",
    "    \n",
    "    \n",
    "\n",
    "      Shadow_Price = np.asarray(Shadow_Price).reshape(-1, 1)\n",
    "      In_Cons_Num = np.asarray(In_Cons_Num).reshape(-1, 1)\n",
    "      In_Cols_Num = np.asarray(In_Cols_Num).reshape(-1, 1)\n",
    "      ColumnSol_Val = np.asarray(ColumnSol_Val).reshape(-1, 1)\n",
    "      cost_c = np.asarray(cost_c).reshape(-1, 1)\n",
    "      stay_in = np.asarray(stay_in).reshape(-1, 1)\n",
    "      stay_out = np.asarray(stay_out).reshape(-1, 1)\n",
    "\n",
    "\n",
    "      from sklearn.preprocessing import MinMaxScaler\n",
    "      # from sklearn.preprocessing import StandardScalar\n",
    "\n",
    "\n",
    "      Scaler_SP = MinMaxScaler()\n",
    "      Scaler_SP.fit(Shadow_Price)\n",
    "      Shadow_Price = Scaler_SP.transform(Shadow_Price)\n",
    "      Scaler_IConsN = MinMaxScaler()\n",
    "      Scaler_IConsN.fit(In_Cons_Num)\n",
    "      In_Cons_Num = Scaler_IConsN.transform(In_Cons_Num)\n",
    "      Scaler_IColsN = MinMaxScaler()\n",
    "      Scaler_IColsN.fit(In_Cols_Num)\n",
    "      In_Cols_Num = Scaler_IColsN.transform(In_Cols_Num)\n",
    "      Scaler_CSV = MinMaxScaler()\n",
    "      Scaler_CSV.fit(ColumnSol_Val)\n",
    "      ColumnSol_Val = Scaler_CSV.transform(ColumnSol_Val)\n",
    "      Scaler_W = MinMaxScaler()\n",
    "      Scaler_W.fit(cost_c)\n",
    "      cost_c = Scaler_W.transform(cost_c)\n",
    "\n",
    "      Scaler_si = MinMaxScaler()\n",
    "      Scaler_si.fit(stay_in)\n",
    "      stay_in = Scaler_si.transform(stay_in)\n",
    "\n",
    "      Scaler_out = MinMaxScaler()\n",
    "      Scaler_out.fit(stay_out)\n",
    "      stay_out = Scaler_out.transform(stay_out)\n",
    "\n",
    "\n",
    "      Shadow_Price = list(Shadow_Price.T[0])\n",
    "      In_Cons_Num = list(In_Cons_Num.T[0])\n",
    "      In_Cols_Num = list(In_Cols_Num.T[0])\n",
    "      ColumnSol_Val = list(ColumnSol_Val.T[0])\n",
    "      cost_c = list(cost_c.T[0])\n",
    "      stay_in = list(stay_in.T[0])\n",
    "      stay_out = list(stay_out.T[0])\n",
    "\n",
    "\n",
    "      ### constraint nodes\n",
    "      for j in range(cons_num):\n",
    "          con_feat = []\n",
    "          con_feat.append(Shadow_Price[j])\n",
    "          con_feat.append(In_Cols_Num[j])\n",
    "          cons_features.append(con_feat)\n",
    "\n",
    "      \n",
    "      ### normalize here for each information\n",
    "      for i in range(col_num):\n",
    "          col_feat = []\n",
    "          col_feat.append(In_Cons_Num[i])\n",
    "          col_feat.append(ColumnSol_Val[i])\n",
    "          col_feat.append(cost_c[i])\n",
    "          col_feat.append(stay_in[i])\n",
    "          col_feat.append(stay_out[i])\n",
    "          col_feat.append(just_left[i])\n",
    "          col_feat.append(just_enter[i])\n",
    "          col_feat.append(is_action[i])\n",
    "\n",
    "          column_features.append(col_feat)\n",
    "      \n",
    "      ## get edges going\n",
    "      for m in range(len(MatA[0])):\n",
    "          for n in range(len(MatA)):\n",
    "              if MatA[n][m]!=0:\n",
    "                  # then mth column is connected to nth cons\n",
    "                  edge_indices[0].append(m)\n",
    "                  edge_indices[1].append(n)\n",
    "\n",
    "      edge_indices = np.asarray(edge_indices)\n",
    "      edge_indices[[0, 1]] = edge_indices[[1, 0]]\n",
    "\n",
    "\n",
    "      cons_features=np.asarray(cons_features)\n",
    "      column_features=np.asarray(column_features)\n",
    "\n",
    "      ## need this total_added for reading the Q values, need actions to select onne pattern after read Q values\n",
    "      aug_state, action_info = ((cons_features, edge_indices, column_features),(total_added,actions))\n",
    "      return aug_state, action_info\n",
    "\n",
    "  def policy(self):\n",
    "\n",
    "      return random.choice(self.A)\n",
    "      # return random.sample(self.A, k=1)[0]\n",
    "  \n",
    "  def perform_policy(self, s, Q = None, epsilon = 0.05):\n",
    "      action = self.policy()\n",
    "      return action\n",
    "\n",
    "\n",
    "  def act(self, a0):\n",
    "      ## get the current super state \n",
    "      s0_augmented, action_info_0 = self.S\n",
    "      total_0 = deepcopy(action_info_0[0])\n",
    "      # print(s0_augmented)\n",
    "\n",
    "      ## step change the environnment, update all the information used for agent to construct state\n",
    "      r, is_done = self.env.step(a0)\n",
    "\n",
    "      s1_augmented, action_info_1 = self.get_aug_state()\n",
    "      total_1 = action_info_1[0]\n",
    "      trans = Transition(s0_augmented, a0, r, is_done, s1_augmented, action_info_0, total_0, total_1)\n",
    "      total_reward = self.experience.push(trans)\n",
    "      self.S = s1_augmented, action_info_1\n",
    "\n",
    "      return s1_augmented, r, is_done, total_reward\n",
    "\n",
    "  def learning_method(self,VRP_instance, gamma = 0.9, alpha = 1e-3, epsilon = 0.05):\n",
    "      #self.state = self.env.reset()\n",
    "      ## initialize an environment\n",
    "\n",
    "\n",
    "      self.env = VRP_instance\n",
    "\n",
    "\n",
    "      self.S = self.get_aug_state()\n",
    "\n",
    "      ### initialize before calling\n",
    "      # self.env.initialize()\n",
    "\n",
    "      self.A = self.env.available_action[0]\n",
    "\n",
    "      s0 = self.S\n",
    "      a0 = self.perform_policy(s0, epsilon)\n",
    "      time_in_episode, total_reward = 0, 0\n",
    "      is_done = False\n",
    "      while not is_done:\n",
    "          # act also update self.S\n",
    "          s1, r1, is_done, total_reward = self.act(a0)\n",
    "          self.A = self.env.available_action[0]\n",
    "          # if self.A == []:\n",
    "          #     break;\n",
    "          a1 = self.perform_policy(s1, epsilon)\n",
    "          s0, a0 = s1, a1\n",
    "          time_in_episode += 1\n",
    "\n",
    "          # actions,reduced_costs = deepcopy(self.env.available_action)\n",
    "\n",
    "      return time_in_episode, total_reward  \n",
    "    \n",
    "\n",
    "  def _decayed_epsilon(self,cur_episode: int, \n",
    "                            min_epsilon: float, \n",
    "                            max_epsilon: float, \n",
    "                            target_episode: int) -> float: \n",
    "      slope = (min_epsilon - max_epsilon) / (target_episode)\n",
    "      intercept = max_epsilon\n",
    "      return max(min_epsilon, slope * cur_episode + intercept)        \n",
    "      \n",
    "                      \n",
    "  def learning(self,  epsilon = 0.05, decaying_epsilon = True, gamma = 0.9, \n",
    "                learning_rate = 3e-4, max_episode_num = 153, display = False, min_epsilon = 1e-2, min_epsilon_ratio = 0.8, model_index = 0):\n",
    "      total_time,  episode_reward, num_episode = 0,0,0\n",
    "      total_times, episode_rewards, num_episodes,history = [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "      schedule = np.load(\"train_test/schedule.npy\")\n",
    "\n",
    "      for i in range(max_episode_num):\n",
    "          if epsilon is None:\n",
    "              epsilon = 1e-10\n",
    "          elif decaying_epsilon:\n",
    "              #epsilon = 1.0 / (1 + num_episode)\n",
    "              epsilon = self._decayed_epsilon(cur_episode = num_episode+1,\n",
    "                                              min_epsilon = min_epsilon,\n",
    "                                              max_epsilon = epsilon,\n",
    "                                              target_episode = int(max_episode_num * min_epsilon_ratio))\n",
    "          \n",
    "\n",
    "         \n",
    "          #### read_file    \n",
    "\n",
    "          # schedule = np.load(\"/content/drive/MyDrive/ICML_VRP/schedule.npy\")\n",
    "          n,problem_name = schedule[i]\n",
    "\n",
    "          try:\n",
    "              VRP_instance = VRP(problem_name,int(n))\n",
    "          except:\n",
    "              print(problem_name +\" is not found, so skip\")\n",
    "              continue\n",
    "\n",
    "          too_long = VRP_instance.initialize()[2]\n",
    "\n",
    "          if too_long:\n",
    "              print(\"Skip instance {} in episode {}\".format(problem_name,i))\n",
    "              continue\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "          \n",
    "          time_in_episode, episode_reward = self.learning_method(VRP_instance, \\\n",
    "                gamma = gamma, learning_rate = learning_rate, epsilon = epsilon, display = display)\n",
    "          # total_time += time_in_episode\n",
    "          num_episode += 1\n",
    "\n",
    "          total_times.append(time_in_episode)\n",
    "          episode_rewards.append(episode_reward)\n",
    "          num_episodes.append(num_episode)\n",
    "          history.append(VRP_instance.objVal_history[-1])\n",
    "\n",
    "\n",
    "          print(\"Episode: \" + str(i) + \" takes \" + str(time_in_episode) +\" steps with obj \"+str(VRP_instance.objVal_history[-1]))\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      model_save_name = 'Model.pt'\n",
    "      path_model = 'Saved_results/{model_save_name}'\n",
    "      self.target_Q.save_state(path_model)\n",
    "\n",
    "    \n",
    " \n",
    "      return  total_times, episode_rewards, num_episodes\n",
    "\n",
    "\n",
    "  def sample(self, batch_size = 32):\n",
    "      return self.experience.sample(batch_size)\n",
    "\n",
    "  @property\n",
    "  def total_trans(self):\n",
    "      return self.experience.total_trans\n",
    "  \n",
    "  def last_episode_detail(self):\n",
    "      self.experience.last_episode.print_detail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNCgRxhiw6b3"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "class DQNAgent(Agent):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, env,\n",
    "                       capacity,\n",
    "                       hidden_dim,\n",
    "                       batch_size,\n",
    "                       epochs,\n",
    "                       embedding_size,\n",
    "                       cons_num_features,\n",
    "                       vars_num_features,\n",
    "                       learning_rate,\n",
    "                       seed_):\n",
    "\n",
    "        super(DQNAgent, self).__init__(env, capacity)\n",
    "        self.embedding_size = embedding_size \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cons_num_features = cons_num_features\n",
    "        self.vars_num_features = vars_num_features\n",
    "        self.lr = learning_rate\n",
    "        self.seed = seed_\n",
    "\n",
    "        self.behavior_Q = BipartiteGNN(embedding_size = self.embedding_size, cons_num_features = self.cons_num_features, \n",
    "        vars_num_features = self.vars_num_features, learning_rate = self.lr, seed = self.seed)\n",
    "\n",
    "        self.target_Q = BipartiteGNN(embedding_size = self.embedding_size, cons_num_features = self.cons_num_features, \n",
    "        vars_num_features = self.vars_num_features, learning_rate = self.lr, seed = self.seed)\n",
    "        self._update_target_Q()\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def _update_target_Q(self):\n",
    "       \n",
    "        '''\n",
    "        '''\n",
    "        self.target_Q.set_weights(deepcopy(self.behavior_Q.variables))\n",
    "        # self.target_Q = self.behavior_Q.clone()\n",
    "        \n",
    "    \n",
    "    ## s is the super s0, A is the list containing all actions\n",
    "    def policy(self, action_info, s, epsilon = None):\n",
    "\n",
    "        total_added, Actions = action_info\n",
    "        Q_s = self.behavior_Q(s)\n",
    "        Q_s_for_action = Q_s[-total_added::]\n",
    "\n",
    "        rand_value = np.random.random()\n",
    "        if epsilon is not None and rand_value < epsilon:\n",
    "            return random.choice(list(Actions))\n",
    "        else:\n",
    "            idx = int(np.argmax(Q_s_for_action))\n",
    "            return Actions[idx]\n",
    "\n",
    "\n",
    "    ## s is the super s0, A is the list containing all actions\n",
    "    ### need action info 0 and total 1 (total_1 to get max Q_1, action_info_0 to get update index)\n",
    "    def get_max(self,  total_1, s):\n",
    "        Q_s = self.target_Q.call(s)\n",
    "        Q_s_for_action = Q_s[-total_1::]\n",
    "        return np.max(Q_s_for_action)\n",
    "\n",
    "    ## this method is used to get target in _learn_from_memory function\n",
    "    ## select the max number from last few items from Q_matrix for each row, based on last_index_list\n",
    "    \n",
    "    def _learn_from_memory(self, gamma, learning_rate):\n",
    "\n",
    "        ## trans_pieces is a list of transitions\n",
    "        trans_pieces = self.sample(self.batch_size)  # Get transition data\n",
    "        states_0 = np.vstack([x.s0 for x in trans_pieces]) # as s0 is a list, so vstack\n",
    "        actions_0 = np.array([x.a0 for x in trans_pieces]) \n",
    "        reward_1 = np.array([x.reward for x in trans_pieces])\n",
    "        is_dones = np.array([x.is_done for x in trans_pieces])\n",
    "        states_1 = np.vstack([x.s1 for x in trans_pieces])\n",
    "        action_info = np.vstack([x.action_info_0 for x in trans_pieces])\n",
    "        totals_0 = np.vstack([x.total_0 for x in trans_pieces])\n",
    "        totals_1 = np.vstack([x.total_1 for x in trans_pieces])\n",
    "\n",
    "        y_batch = []\n",
    "        for i in range(len(states_0)):\n",
    "          \n",
    "            ### get the index of action that is taken at s0\n",
    "            acts_0 = action_info[i][1]\n",
    "            act_0 = list(actions_0[i])\n",
    "\n",
    "            idx = 0\n",
    "            for act in acts_0:\n",
    "                if act==act_0:\n",
    "                    break\n",
    "                idx+=1\n",
    "\n",
    "            y = self.target_Q.call(states_0[i]).numpy()\n",
    "            #### set the non action terms to be 0 \n",
    "            y[0:-totals_0[i][0]] = 0\n",
    "\n",
    "            if is_dones[i]:\n",
    "                Q_target = reward_1[i]\n",
    "            else:\n",
    "                ### the number of actions for state 1 is used to get Q_target\n",
    "                Q_max = self.get_max(totals_1[i][0], states_1[i])\n",
    "                Q_target = reward_1[i] + gamma * Q_max\n",
    "\n",
    "            y[-totals_0[i][0]+idx] = Q_target\n",
    "            \n",
    "            y_batch.append(np.asarray(y))\n",
    "\n",
    "        y_batch= np.asarray(y_batch)\n",
    "        X_batch = states_0\n",
    "        \n",
    "        loss = self.behavior_Q.train_or_test(X_batch, y_batch, totals_0, actions_0, action_info, True)\n",
    "        # print(\"The loss is,\", loss)\n",
    "        self._update_target_Q()\n",
    "      \n",
    "        return loss\n",
    "\n",
    "    #### the learning code\n",
    "    def learning_method(self, instance, gamma, learning_rate, epsilon, \n",
    "                        display):\n",
    "\n",
    "        epochs = self.epochs\n",
    "        ###########\n",
    "        self.env = instance\n",
    "        self.S = self.get_aug_state()\n",
    "        \n",
    "        time_in_episode, total_reward = 0, 0\n",
    "        is_done = False\n",
    "        loss = 0\n",
    "        while not is_done:\n",
    "            s0_aug = self.S[0]\n",
    "            action_info = self.S[1]\n",
    "            ### a0 is selected based on behavior_Q\n",
    "            # print(action_info[1])\n",
    "            if len(action_info[1]) == 0:\n",
    "                ## if no available actions,end this episode\n",
    "                break;\n",
    "            \n",
    "            a0 = self.policy(action_info, s0_aug, epsilon)\n",
    "            print(\"Added route is {} out of {}\".format(a0,len(action_info[1])))\n",
    "\n",
    "            s1_augmented, r, is_done, total_reward = self.act(a0)\n",
    "\n",
    "\n",
    "            if self.total_trans > self.batch_size:\n",
    "                for e in range(epochs):\n",
    "                    loss += self._learn_from_memory(gamma, learning_rate)\n",
    "                # loss/=epochs\n",
    "            # s0 = s1\n",
    "            time_in_episode += 1\n",
    "\n",
    "        loss /= (time_in_episode*epochs)\n",
    "        print(\"The loss is,\",loss)\n",
    "        if display:\n",
    "            print(\"epsilon:{:3.2f},loss:{:3.2f},{}\".format(epsilon,loss,self.experience.last_episode))\n",
    "        return time_in_episode, total_reward  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Rier96Iw8jC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "class BipartiteGNN(K.Model):\n",
    "\n",
    "    '''\n",
    "    Initialization of the different modules and attributes\n",
    "    Attributes : \n",
    "    - embedding_size : Embedding size for the intermediate layers of the neural networks\n",
    "    - cons_num_features : Number of constraint features, the constraints data matrix expected has the shape (None,cons_num_features)\n",
    "    - vars_num_features : Number of variable features, the variables data matrix expected has the shape (None,vars_num_features)\n",
    "    - learning_rate : Optimizer learning rate\n",
    "    - activation : Activation function used in the neurons\n",
    "    - initializer : Weights initializer\n",
    "    '''\n",
    "    def __init__(self, embedding_size = 32, cons_num_features = 2, \n",
    "        vars_num_features = 9, learning_rate = 1e-3, seed = 0,\n",
    "        activation = K.activations.relu, initializer = K.initializers.Orthogonal):\n",
    "        self.seed_value = seed\n",
    "        tf.random.set_seed(self.seed_value)\n",
    "        super(BipartiteGNN, self).__init__()\n",
    "\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.cons_num_features = cons_num_features\n",
    "        self.vars_num_features = vars_num_features\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "\n",
    "        self.initializer = initializer(seed=self.seed_value)\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=self.learning_rate) \n",
    "\n",
    "        # constraints embedding layer\n",
    "        self.cons_embedding = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),\n",
    "        ])\n",
    "\n",
    "        # variables/columns embedding layer\n",
    "        self.var_embedding = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),\n",
    "        ])\n",
    "\n",
    "        # NN responsible for the intermediate updates\n",
    "        self.join_features_NN = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer)\n",
    "        ])\n",
    "\n",
    "        # Representations updater for the constraints, called after the agregation\n",
    "        self.cons_representation_NN = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),  \n",
    "        ])\n",
    "        # Representations updater for the variables/columns, called after the agregation\n",
    "        self.vars_representation_NN = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),  \n",
    "        ])\n",
    "\n",
    "        # NN for final output, i.e., one unit logit output\n",
    "        self.output_module = K.Sequential([\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),\n",
    "            K.layers.Dense(units=self.embedding_size, activation=self.activation, kernel_initializer=self.initializer),\n",
    "            K.layers.Dense(units=1, activation=None, kernel_initializer=self.initializer)\n",
    "        ])\n",
    "\n",
    "        # Build of the input shapes of all the NNs\n",
    "        self.build()\n",
    "\n",
    "        # Order set for loading/saving the model\n",
    "        self.variables_topological_order = [v.name for v in self.variables]\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Build function, sets the input shapes. Called during initialization\n",
    "    '''\n",
    "    def build(self):\n",
    "        self.cons_embedding.build([None, self.cons_num_features])\n",
    "        self.var_embedding.build([None, self.vars_num_features])\n",
    "        self.join_features_NN.build([None, self.embedding_size*2])\n",
    "        self.cons_representation_NN.build([None, self.embedding_size*2])\n",
    "        self.vars_representation_NN.build([None, self.embedding_size*2])\n",
    "        self.output_module.build([None, self.embedding_size])\n",
    "        self.built = True\n",
    "\n",
    "    '''\n",
    "    Main function taking as an input a tuple containing the three matrices :\n",
    "    - cons_features : Matrix of constraints features, shape : (None, cons_num_features)\n",
    "    - edge_indices : Edge indices linking constraints<->variables, shape : (2, None)\n",
    "    - vars_features : Matrix of variables features, shape : (None, vars_num_features)\n",
    "\n",
    "    Output : logit vector for the variables nodes, shape (None,1)\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        # print(\"The code is running\", inputs[0].shape)\n",
    "\n",
    "        cons_features, edge_indices, vars_features = inputs\n",
    "        # print(\"#######################\")\n",
    "        # print(cons_features)\n",
    "        # print(edge_indices)\n",
    "        # print(vars_features)\n",
    "        # print(\"#######################\")\n",
    "        # Nodes embedding, constraints and variables\n",
    "        cons_features = self.cons_embedding(cons_features)\n",
    "        vars_features = self.var_embedding(vars_features)\n",
    "\n",
    "        # ==== First Pass : Variables -> Constraints ====\n",
    "        # compute joint representations\n",
    "        joint_features = self.join_features_NN(\n",
    "                tf.concat([\n",
    "                    tf.gather(\n",
    "                        cons_features,\n",
    "                        axis=0,\n",
    "                        indices=edge_indices[0])\n",
    "                    ,\n",
    "                    tf.gather(\n",
    "                        vars_features,\n",
    "                        axis=0,\n",
    "                        indices=edge_indices[1])\n",
    "                    ### change this number to edge weights (patterns)\n",
    "                ],1)\n",
    "        )\n",
    "\n",
    "        # Aggregation step\n",
    "        output_cons = tf.scatter_nd(\n",
    "            updates=joint_features,\n",
    "            indices=tf.expand_dims(edge_indices[0], axis=1),\n",
    "            shape=[cons_features.shape[0], self.embedding_size]\n",
    "        )\n",
    "        # Constraints representations update\n",
    "        output_cons = self.cons_representation_NN(tf.concat([output_cons,cons_features],1))\n",
    "\n",
    "\n",
    "\n",
    "        # ==== Second Pass : Constraints -> Variables ====\n",
    "        # compute joint representations\n",
    "        joint_features = self.join_features_NN(\n",
    "                tf.concat([\n",
    "                    tf.gather(\n",
    "                        output_cons,\n",
    "                        axis=0,\n",
    "                        indices=edge_indices[0])\n",
    "                    ,\n",
    "                    tf.gather(\n",
    "                        vars_features,\n",
    "                        axis=0,\n",
    "                        indices=edge_indices[1])\n",
    "                ],1)\n",
    "        )\n",
    "\n",
    "        # Aggregation step\n",
    "        output_vars = tf.scatter_nd(\n",
    "            updates=joint_features,\n",
    "            indices=tf.expand_dims(edge_indices[1], axis=1),\n",
    "            shape=[vars_features.shape[0], self.embedding_size]\n",
    "        )\n",
    "        # Variables representations update\n",
    "        output_vars = self.vars_representation_NN(tf.concat([output_vars,vars_features],1))\n",
    "\n",
    "        # ==== Final output from the variables representations (constraint nodes are ignored)\n",
    "        output = self.output_module(output_vars)\n",
    "        return output\n",
    "\n",
    "    '''\n",
    "    Save model and current weights to a given path\n",
    "    '''\n",
    "    def save_state(self, path):\n",
    "        import pickle\n",
    "        with open(path, 'wb') as f:\n",
    "            for v_name in self.variables_topological_order:\n",
    "                v = [v for v in self.variables if v.name == v_name][0]\n",
    "                pickle.dump(v.numpy(), f)\n",
    "\n",
    "    '''\n",
    "    Load an existing model from a given path\n",
    "    '''\n",
    "    def restore_state(self, path):\n",
    "        import pickle\n",
    "        with open(path, 'rb') as f:\n",
    "            for v_name in self.variables_topological_order:\n",
    "                v = [v for v in self.variables if v.name == v_name][0]\n",
    "                v.assign(pickle.load(f))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        for i in range(len(self.variables_topological_order)):\n",
    "            config[self.variables_topological_order[i]] = self.variables[i]\n",
    "        return config\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(model):\n",
    "        for v_name in self.variables_topological_order:\n",
    "            v = [v for v in model.variables if v.name == v_name][0]\n",
    "            v.assign(config[v])\n",
    "        return model\n",
    "       \n",
    "\n",
    "    '''\n",
    "    Training/Test function\n",
    "    Input: \n",
    "    - data : a batch of data, type : tf.data.Dataset\n",
    "    - train: boolean, True if function called for training (i.e., compute gradients and update weights),\n",
    "                False if called for test\n",
    "    Output:\n",
    "    tuple(Loss, Accuracy, Recall, TNR) : Metrics\n",
    "    '''\n",
    "    def train_or_test(self, data, labels, totals_0, actions_0,action_info, train=False):\n",
    "        mean_loss = 0\n",
    "  \n",
    "        batches_counter = 0\n",
    "\n",
    "        ###########################################################\n",
    "        ### how does this data(a batch) relates to transition data?\n",
    "        ###########################################################\n",
    "        for batch in data:\n",
    "            cons_features, edge_indices, vars_features = batch\n",
    "            input_tuple = (cons_features, edge_indices, vars_features)\n",
    "\n",
    "            total_0 = totals_0[batches_counter]\n",
    "\n",
    "            label = labels[batches_counter]\n",
    "\n",
    "\n",
    "\n",
    "            # When called train=True, compute gradient and update weights\n",
    "            if train:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Get logits from the bipartite GNN model\n",
    "\n",
    "                    ########\n",
    "                    ######### may need to change to self.call?\n",
    "                    logits = self.call(input_tuple)\n",
    "                    # print(total_0)\n",
    "                    label[0:-total_0[0]] =  logits[0:-total_0[0]] ## do not count the loss from the nodes already in the basis\n",
    " \n",
    "                    loss = tf.keras.metrics.mean_squared_error(label,logits) ## should not be mean_squared_error as it's then scaled down by number of nodes\n",
    "                    # loss = (loss * label.shape[0]) / total_0[0]  ## this is a quick fix, as there are far less action nodes compared to \n",
    "                    loss = (loss * label.shape[0])\n",
    "                # Compute gradient and update weights\n",
    "                grads = tape.gradient(target=loss, sources=self.variables)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.variables))\n",
    "            # If no optimizer instance set, no training is performed, give outputs and metrics only\n",
    "            else:\n",
    "                logits = self.call(input_tuple)\n",
    "                loss = tf.keras.metrics.mean_squared_error(label,logits)\n",
    "\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            # Batch loss, accuracy, confusion matrix\n",
    "            mean_loss += loss\n",
    "            batches_counter += 1 \n",
    "            # confusion_mat += confusion_matrix(labels, prediction)\n",
    "\n",
    "        # Batch average loss\n",
    "        mean_loss /= batches_counter\n",
    "        return mean_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqbayszO1c7S"
   },
   "outputs": [],
   "source": [
    "# Model 3:  (300, 0.05, 0.9, 0.001)\n",
    "\n",
    "class PARAMETERS(object):\n",
    "    def __init__(self):\n",
    "        self.seed = 5\n",
    "\n",
    "\n",
    "        ## parameters about neural network\n",
    "        self.lr = 1e-3  ##\n",
    "        self.batch_size = 16\n",
    "        self.hidden_dim = 32\n",
    "        self.epochs = 5\n",
    "        self.embedding_size = 32\n",
    "        self.cons_num_features = 2\n",
    "        self.vars_num_features = 8\n",
    "\n",
    "\n",
    "\n",
    "        ## parameters of RL algorithm\n",
    "        self.gamma = 0.99 ##\n",
    "        self.epsilon = 0.2\n",
    "        self.min_epsilon = 0.2\n",
    "        self.min_epsilon_ratio = 0.99\n",
    "        self.decaying_epsilon = False\n",
    "        self.step_penalty = 1\n",
    "        self.alpha_obj_weight = 5 ##\n",
    "        self.action_pool_size = 10 \n",
    "        self.max_episode_num = 447\n",
    "        self.capacity = 20000 \n",
    "\n",
    "\n",
    "        self.model_index = 3 #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iesHntWfBoa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZRPUvMzxr2b"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Btuza1v2on9"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os.path\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Parameters = PARAMETERS()\n",
    "\n",
    "random.seed(Parameters.seed)\n",
    "np.random.seed(Parameters.seed)\n",
    "\n",
    "epsilon_ = Parameters.epsilon\n",
    "decaying_epsilon_ = Parameters.decaying_epsilon\n",
    "gamma_ = Parameters.gamma\n",
    "alpha_ = Parameters.alpha_obj_weight\n",
    "max_episode_num_ = Parameters.max_episode_num\n",
    "min_epsilon_ = Parameters.min_epsilon\n",
    "min_epsilon_ratio_ = Parameters.min_epsilon_ratio\n",
    "capacity_ =  Parameters.capacity\n",
    "hidden_dim_ = Parameters.hidden_dim\n",
    "batch_size_ = Parameters.batch_size\n",
    "epochs_ = Parameters.epochs\n",
    "embedding_size_ = Parameters.embedding_size\n",
    "cons_num_features_ = Parameters.cons_num_features\n",
    "vars_num_features_ = Parameters.vars_num_features\n",
    "learning_rate_ = Parameters.lr\n",
    "model_index_ = Parameters.model_index\n",
    "seed_fix = Parameters.seed\n",
    "\n",
    "display_ = False\n",
    "\n",
    "\n",
    "### training and saving the data for plotting and model weights (weights and data are saved inside .learning)\n",
    "\n",
    "\n",
    "DQN = DQNAgent(env = None, capacity = capacity_, hidden_dim = hidden_dim_, batch_size = batch_size_, epochs = epochs_, embedding_size = embedding_size_, \n",
    "\t\t\t   cons_num_features = cons_num_features_, vars_num_features = vars_num_features_, learning_rate = learning_rate_, seed_ = seed_fix)\n",
    "\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)     \n",
    "total_times, episode_rewards, num_episodes =  DQN.learning(epsilon = epsilon_, decaying_epsilon = decaying_epsilon_, gamma = gamma_, \n",
    "                learning_rate = learning_rate_, max_episode_num = max_episode_num_, display = display_, min_epsilon = min_epsilon_, min_epsilon_ratio = min_epsilon_ratio_, model_index = model_index_)    \n",
    "\n",
    "time_ends = time.time()\n",
    "\n",
    "### training will take quite some time as the pricing problem in this case (VRPTW) takes more time than pricing problem in CSP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xze8O3ar9yU4"
   },
   "source": [
    "## testing after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGWDUrdP9zzo"
   },
   "outputs": [],
   "source": [
    "\n",
    "Parameters = PARAMETERS()\n",
    "def follow_policy(DQN,action_info, s):\n",
    "    '''DQN selects an action \n",
    "    '''\n",
    "    total_added, Actions = action_info\n",
    "    Q_s = DQN.target_Q(s)\n",
    "    Q_s_for_action = Q_s[-total_added::]\n",
    "    # rand_value = np.random.random()\n",
    "    idx = int(np.argmax(Q_s_for_action))\n",
    "    return Actions[idx]\n",
    "\n",
    "import time\n",
    "def general_compare(DQN_test):\n",
    "\n",
    "    Greedy=[]\n",
    "    # Expert = []\n",
    "    RL=[]\n",
    "\n",
    "    True_obj = [] \n",
    "\n",
    "    print(\"#####################\")\n",
    "    print(\"Starts testing for model\")\n",
    "    print()\n",
    "    \n",
    "    model_save_name ='Model.pt'\n",
    "    schedule_test = np.load('train_test/test.npy',allow_pickle=True)\n",
    "    path_model = 'Saved_results/{model_save_name}'\n",
    " \n",
    "    DQN.target_Q.restore_state(path_model)\n",
    "    DQN.behavior_Q.restore_state(path_model)\n",
    "\n",
    "\n",
    "    for k in range(len(schedule_test)):\n",
    "        print(\"#### {} instance out of {}\".format(k,len(schedule_test)))\n",
    "        \n",
    "        n,problem_name = schedule_test[k]\n",
    "\n",
    "        ################################## Greedy\n",
    "        try:\n",
    "            VRP_instance = VRP(problem_name,int(n))\n",
    "        except:\n",
    "            print(\"Skip as not found\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "        too_long = VRP_instance.initialize()[2]\n",
    "        if too_long:\n",
    "            print(\"skip instance \"+problem_name)\n",
    "            continue\n",
    "        print(\"starts greedy\")\n",
    "\n",
    "        t1 = time.time()\n",
    "        is_done = False\n",
    "        while True:\n",
    "            if is_done:\n",
    "                break\n",
    "\n",
    "            action = VRP_instance.available_action[0][-1]\n",
    "            reward, is_done = VRP_instance.step(action)\n",
    "            print(\"Added route is {} out of {}\".format(action,len(VRP_instance.available_action[0])))\n",
    "        t2 = time.time()\n",
    "\n",
    "        history_opt_g = VRP_instance.objVal_history\n",
    "\n",
    "\n",
    "        obj_greedy = history_opt_g[-1]\n",
    "        steps_g = len(history_opt_g)\n",
    "        print(\"Greedy takes {} steps to reach obj {} with time {}\".format(steps_g,obj_greedy,t2-t1))\n",
    "        # print(\"starts RL\")\n",
    "        \n",
    "        ###################################  RL\n",
    "        try:\n",
    "            VRP_instance2 = VRP(problem_name,int(n))\n",
    "        except:\n",
    "            print(\"Skip as not found\")\n",
    "            continue\n",
    "            \n",
    "        too_long = VRP_instance2.initialize()[2]\n",
    "        t3 = time.time()\n",
    "        DQN.env = VRP_instance2\n",
    "        DQN.S = DQN.get_aug_state()\n",
    "        \n",
    "        is_done = False\n",
    "        while True:\n",
    "            if is_done:\n",
    "                break\n",
    "\n",
    "            action_info = DQN.S[1]\n",
    "            s = DQN.S[0]\n",
    "            action = follow_policy(DQN,action_info,s)\n",
    "            reward, is_done = VRP_instance2.step(action)\n",
    "            DQN.S = DQN.get_aug_state()\n",
    "\n",
    "            print(\"Added route is {} out of {}\".format(action,len(action_info[1])))\n",
    "\n",
    "        t4 = time.time()\n",
    "\n",
    "        history_opt_rl = VRP_instance2.objVal_history\n",
    "\n",
    "        obj_RL = history_opt_rl[-1]\n",
    "        steps_RL = len(history_opt_rl)\n",
    "\n",
    "        print(\"RL takes {} steps to reach obj {} with time {}\".format(steps_RL,obj_RL,t4-t3))\n",
    "        \n",
    "        #### (full history, total number of steps, times, obj value)\n",
    "        Greedy.append((history_opt_g,len(history_opt_g),t2-t1,obj_greedy))\n",
    "        RL.append((history_opt_rl,len(history_opt_rl),t4-t3,obj_RL))\n",
    "\n",
    "        # Expert.append((history_opt_expert,len(history_opt_expert),time4-time3,obj_expert))\n",
    "        print()\n",
    "        print(\"{} steps out of {}\".format(k,len(schedule_test)))\n",
    "        print(\"#########\")\n",
    "        \n",
    "        \n",
    "        ## save results after every 5 instances\n",
    "        if k%5==0:\n",
    "            path = 'Saved_results/data/'\n",
    "            np.save(path+'test_results_ '+str(k),(Greedy,RL))\n",
    "\n",
    "    complete_data = (Greedy,RL)\n",
    "    path = 'Saved_results/data/'\n",
    "    np.save(path+'FULL_TEST_RESULTS_LIST',complete_data)\n",
    "\n",
    "    #### return three lists of tuple: (running time, steps)\n",
    "\n",
    "    return complete_data\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8R66famGH2L"
   },
   "source": [
    "## average result of validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load('Saved_results/data/FULL_TEST_RESULTS_LIST.npy',allow_pickle=True)\n",
    "NAME = np.load('train_test/test.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(vec):\n",
    "  return [vec.mean().round(1), vec.std().round(1)]\n",
    "\n",
    "# def stat(arr):\n",
    "#   return [mean_std(arr[i, :]) for i in range(3)]\n",
    "\n",
    "def stat(arr):\n",
    "  return [mean_std(arr[i, :]) for i in range(2)]\n",
    "\n",
    "\n",
    "def result_table(data):\n",
    "  iternum = data[:, :, 1].astype('float64')\n",
    "  time = data[:, :, 2].astype('float64')\n",
    "  objval = data[:, :, 3].astype('float64')\n",
    "  iter_tab = pd.DataFrame(data = np.asarray(stat(iternum)), columns = [\"Mean\", \"Std\"])\n",
    "  iter_tab.index = [\"Greedy\", \"RL\"]\n",
    "  time_tab = pd.DataFrame(data = np.asarray(stat(time)), columns = [\"Mean\", \"Std\"])\n",
    "  time_tab.index = [\"Greedy\", \"RL\"]\n",
    "  objval_tab = pd.DataFrame(data = np.asarray(stat(objval)), columns = [\"Mean\", \"Std\"])\n",
    "  objval_tab.index = [\"Greedy\", \"RL\"]\n",
    "  return iter_tab, time_tab, objval_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tabs = result_table(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greedy</th>\n",
       "      <td>135.5</td>\n",
       "      <td>101.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL</th>\n",
       "      <td>76.9</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean    Std\n",
       "Greedy  135.5  101.9\n",
       "RL       76.9   38.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tabs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greedy</th>\n",
       "      <td>3635.1</td>\n",
       "      <td>4837.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL</th>\n",
       "      <td>1917.9</td>\n",
       "      <td>1963.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean     Std\n",
       "Greedy  3635.1  4837.9\n",
       "RL      1917.9  1963.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tabs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greedy</th>\n",
       "      <td>466.8</td>\n",
       "      <td>142.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL</th>\n",
       "      <td>466.8</td>\n",
       "      <td>142.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean    Std\n",
       "Greedy  466.8  142.1\n",
       "RL      466.8  142.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tabs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RLCG_VRP_submit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
